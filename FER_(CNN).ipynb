{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabir-al-nahian/emotion-recognition/blob/main/FER_(CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R3K-e0JcPlg",
        "outputId": "57637af1-26fb-4573-9017-9a0979242f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRBU_Ewfccb7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the image data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Facial Emotion Recognition/train',\n",
        "    target_size=(48, 48),\n",
        "    batch_size=64,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Facial Emotion Recognition/test',\n",
        "    target_size=(48, 48),\n",
        "    batch_size=64,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtmHrbhn72XC",
        "outputId": "f386699a-028a-4834-9215-184110d28533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_net(optim):\n",
        "    \"\"\"\n",
        "    This is a Deep Convolutional Neural Network (DCNN). For generalization purpose I used dropouts in regular intervals.\n",
        "    I used `ELU` as the activation because it avoids dying relu problem but also performed well as compared to LeakyRelu\n",
        "    atleast in this case. `he_normal` kernel initializer is used as it suits ELU. BatchNormalization is also used for better\n",
        "    results.\n",
        "    \"\"\"\n",
        "    net = Sequential(name='DCNN')\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5,5),\n",
        "            input_shape=(48, 48, 1),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_1'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_1'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5,5),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_2'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_2'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n",
        "    net.add(Dropout(0.4, name='dropout_1'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_3'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_3'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_4'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_4'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n",
        "    net.add(Dropout(0.4, name='dropout_2'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_5'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_5'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_6'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_6'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n",
        "    net.add(Dropout(0.5, name='dropout_3'))\n",
        "\n",
        "    net.add(Flatten(name='flatten'))\n",
        "\n",
        "    net.add(\n",
        "        Dense(\n",
        "            128,\n",
        "            activation='elu',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='dense_1'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_7'))\n",
        "\n",
        "    net.add(Dropout(0.6, name='dropout_4'))\n",
        "\n",
        "    net.add(\n",
        "        Dense(\n",
        "            7,\n",
        "            activation='softmax',\n",
        "            name='out_layer'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    net.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=optim,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    net.summary()\n",
        "\n",
        "    return net"
      ],
      "metadata": {
        "id": "hyWKZCQ2x3AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0.00005,\n",
        "    patience=11,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=7,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "]"
      ],
      "metadata": {
        "id": "MlskYlEXInid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhZMchl3ixt-"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "\n",
        "batch_size = 32 #batch size of 32 performs the best.\n",
        "optims = [\n",
        "    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n",
        "    optimizers.Adam(0.001),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = build_net(optims[1])\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
        "    epochs=60,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.n // test_generator.batch_size,\n",
        "    callbacks=callbacks,\n",
        "    use_multiprocessing=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "8QexDPBimm8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TztLFpOFi8NU"
      },
      "outputs": [],
      "source": [
        "model.save('CNN_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ5idq-1i8PU"
      },
      "outputs": [],
      "source": [
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "fig.set_size_inches(12,4)\n",
        "\n",
        "ax[0].plot(history.history['accuracy'])\n",
        "ax[0].plot(history.history['val_accuracy'])\n",
        "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_title('Training Loss vs Validation Loss')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E7_hB7si8LE"
      },
      "outputs": [],
      "source": [
        "from keras.utils import load_img\n",
        "import numpy as np\n",
        "\n",
        "img = load_img(\"/content/drive/MyDrive/Facial Emotion Recognition/test/disgust/PrivateTest_50594067.jpg\",target_size = (48,48),color_mode = \"grayscale\")\n",
        "img = np.array(img)\n",
        "plt.imshow(img)\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY7FpMEDi8I8"
      },
      "outputs": [],
      "source": [
        "training_set.class_indices\n",
        "label_dict = ['angry', 'disgust', 'fear','happy', 'neutral', 'sad', 'surprise']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Day9JZyHi8Gk"
      },
      "outputs": [],
      "source": [
        "from keras.utils import img_to_array\n",
        "test_image = img_to_array(img)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)\n",
        "result[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtiRxjR2i8EM"
      },
      "outputs": [],
      "source": [
        "res = np.argmax(result[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex4IVUjQi8CM"
      },
      "outputs": [],
      "source": [
        "print('predicted Label for that image is: {}'.format(label_dict[res]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTq-saQ-i8AE"
      },
      "outputs": [],
      "source": [
        "train_loss, train_acc = model.evaluate(training_set)\n",
        "test_loss, test_acc   = model.evaluate(test_set)\n",
        "print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_acc*100, test_acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWC8dFOTdCgm"
      },
      "outputs": [],
      "source": [
        "# Get the true labels for the validation set\n",
        "true_labels = val_generator.classes\n",
        "\n",
        "# Predict the labels for the validation set\n",
        "predicted_labels = model.predict(val_generator).argmax(axis=1)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "print(\"F1 score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGHMbFA8dCdG"
      },
      "outputs": [],
      "source": [
        "cf_matrix = sklearn.metrics.confusion_matrix(Y_test, pred)\n",
        "sns.heatmap(cf_matrix, cmap = 'Blues', linewidth = 1, annot = True, xticklabels=class_names, yticklabels=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFtbBOjXimvZ",
        "outputId": "c5f3d407-c63d-43b6-ec67-fcadbe8f370f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Facial Emotion Recognition/test',\n",
        "    target_size = (48,48),\n",
        "    batch_size = 128,\n",
        "    color_mode = \"grayscale\",\n",
        "    class_mode = 'categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6j6vc9_im1x",
        "outputId": "384d81d5-ebbe-4d6d-9f55-57f132ad8ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,   ## rescale or normalize the images pixels, by dividing them 255\n",
        "    shear_range = 0.2,  ## angle for slant of image in degrees\n",
        "    zoom_range = 0.2,   ## for zoom in or out\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Facial Emotion Recognition/train',   ## give path of training set\n",
        "    target_size=(48,48),      ## target_size of image in which you want\n",
        "    batch_size=128,\n",
        "    color_mode = \"grayscale\",\n",
        "    class_mode = 'categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X9cXqlFJFX5"
      },
      "outputs": [],
      "source": [
        "#Build the convolution network architecture:\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}